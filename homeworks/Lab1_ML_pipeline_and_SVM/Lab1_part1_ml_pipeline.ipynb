{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment â„–1, part 1\n",
    "\n",
    "This lab assignment consists of several parts. You are supposed to make some transformations, train some models, estimate the quality of the models and explain your results.\n",
    "\n",
    "Several comments:\n",
    "* Don't hesitate to ask questions, it's a good practice.\n",
    "* No private/public sharing, please. The copied assignments will be graded with 0 points.\n",
    "* Blocks of this lab will be graded separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*This is the first part of the assignment. Second part is waiting for you in the same directory.*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-512ba712fc0fc065",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Part 1. Data preprocessing, model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b656a4266174b009",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1. Reading the data\n",
    "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If on colab, uncomment the following lines\n",
    "\n",
    "# ! wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/basic_f20/homeworks_basic/Lab1_ML_pipeline_and_SVM/car_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(846, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(846, 19) (846,)\n(549, 19) (549,) (297, 19) (297,)\n"
     ]
    }
   ],
   "source": [
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88b1a0f688568f2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     0    1   2    3    4   5   6    7   8   9    10   11   12   13  14  15  \\\n",
       "0   807  103  51  105  174  56  11  210  32  24  163  222  650  222  73   8   \n",
       "1   380   80  39   60  122  56   6  139  49  18  131  151  281  142  80   0   \n",
       "2   376  104  51  108  193  59  11  217  31  24  163  232  694  203  72  15   \n",
       "3   799   92  39   76  180  71   6  152  43  19  131  179  350  143  72   6   \n",
       "4    50   78  38   63  115  51   6  142  47  19  130  162  299  146  77   2   \n",
       "5   417   96  36   74  183  70   6  149  43  19  127  178  341  127  69   0   \n",
       "6   483   86  38   76  143  59   8  142  47  18  131  167  301  138  71   5   \n",
       "7   242   85  42   59  132  58   7  149  46  19  144  166  320  172  83   8   \n",
       "8    88   91  42   84  209  75   6  171  38  20  138  189  446  161  69   3   \n",
       "9   264  103  49  100  194  60  10  185  35  22  160  202  518  178  62  13   \n",
       "10  763  102  52   98  225  71  10  214  31  24  164  228  682  199  71   0   \n",
       "11  201   90  36   74  171  60   8  157  42  19  128  177  367  123  61   6   \n",
       "12  818   95  43   96  202  65  10  189  35  22  143  217  534  166  71   6   \n",
       "13  306  106  48  107  202  61  10  207  32  24  153  227  635  200  70   5   \n",
       "14  285   89  48   85  189  64   8  169  39  20  153  188  427  190  64  16   \n",
       "\n",
       "    16   17   18  \n",
       "0    9  187  196  \n",
       "1    5  179  186  \n",
       "2   22  190  201  \n",
       "3   14  195  200  \n",
       "4    4  181  185  \n",
       "5   17  201  205  \n",
       "6   10  189  196  \n",
       "7    4  179  182  \n",
       "8   12  196  201  \n",
       "9    8  198  208  \n",
       "10  16  187  196  \n",
       "11  21  197  204  \n",
       "12  27  190  197  \n",
       "13  28  190  203  \n",
       "14   5  195  201  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>807</td>\n      <td>103</td>\n      <td>51</td>\n      <td>105</td>\n      <td>174</td>\n      <td>56</td>\n      <td>11</td>\n      <td>210</td>\n      <td>32</td>\n      <td>24</td>\n      <td>163</td>\n      <td>222</td>\n      <td>650</td>\n      <td>222</td>\n      <td>73</td>\n      <td>8</td>\n      <td>9</td>\n      <td>187</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>380</td>\n      <td>80</td>\n      <td>39</td>\n      <td>60</td>\n      <td>122</td>\n      <td>56</td>\n      <td>6</td>\n      <td>139</td>\n      <td>49</td>\n      <td>18</td>\n      <td>131</td>\n      <td>151</td>\n      <td>281</td>\n      <td>142</td>\n      <td>80</td>\n      <td>0</td>\n      <td>5</td>\n      <td>179</td>\n      <td>186</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>376</td>\n      <td>104</td>\n      <td>51</td>\n      <td>108</td>\n      <td>193</td>\n      <td>59</td>\n      <td>11</td>\n      <td>217</td>\n      <td>31</td>\n      <td>24</td>\n      <td>163</td>\n      <td>232</td>\n      <td>694</td>\n      <td>203</td>\n      <td>72</td>\n      <td>15</td>\n      <td>22</td>\n      <td>190</td>\n      <td>201</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>799</td>\n      <td>92</td>\n      <td>39</td>\n      <td>76</td>\n      <td>180</td>\n      <td>71</td>\n      <td>6</td>\n      <td>152</td>\n      <td>43</td>\n      <td>19</td>\n      <td>131</td>\n      <td>179</td>\n      <td>350</td>\n      <td>143</td>\n      <td>72</td>\n      <td>6</td>\n      <td>14</td>\n      <td>195</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>78</td>\n      <td>38</td>\n      <td>63</td>\n      <td>115</td>\n      <td>51</td>\n      <td>6</td>\n      <td>142</td>\n      <td>47</td>\n      <td>19</td>\n      <td>130</td>\n      <td>162</td>\n      <td>299</td>\n      <td>146</td>\n      <td>77</td>\n      <td>2</td>\n      <td>4</td>\n      <td>181</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>417</td>\n      <td>96</td>\n      <td>36</td>\n      <td>74</td>\n      <td>183</td>\n      <td>70</td>\n      <td>6</td>\n      <td>149</td>\n      <td>43</td>\n      <td>19</td>\n      <td>127</td>\n      <td>178</td>\n      <td>341</td>\n      <td>127</td>\n      <td>69</td>\n      <td>0</td>\n      <td>17</td>\n      <td>201</td>\n      <td>205</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>483</td>\n      <td>86</td>\n      <td>38</td>\n      <td>76</td>\n      <td>143</td>\n      <td>59</td>\n      <td>8</td>\n      <td>142</td>\n      <td>47</td>\n      <td>18</td>\n      <td>131</td>\n      <td>167</td>\n      <td>301</td>\n      <td>138</td>\n      <td>71</td>\n      <td>5</td>\n      <td>10</td>\n      <td>189</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>242</td>\n      <td>85</td>\n      <td>42</td>\n      <td>59</td>\n      <td>132</td>\n      <td>58</td>\n      <td>7</td>\n      <td>149</td>\n      <td>46</td>\n      <td>19</td>\n      <td>144</td>\n      <td>166</td>\n      <td>320</td>\n      <td>172</td>\n      <td>83</td>\n      <td>8</td>\n      <td>4</td>\n      <td>179</td>\n      <td>182</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>88</td>\n      <td>91</td>\n      <td>42</td>\n      <td>84</td>\n      <td>209</td>\n      <td>75</td>\n      <td>6</td>\n      <td>171</td>\n      <td>38</td>\n      <td>20</td>\n      <td>138</td>\n      <td>189</td>\n      <td>446</td>\n      <td>161</td>\n      <td>69</td>\n      <td>3</td>\n      <td>12</td>\n      <td>196</td>\n      <td>201</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>264</td>\n      <td>103</td>\n      <td>49</td>\n      <td>100</td>\n      <td>194</td>\n      <td>60</td>\n      <td>10</td>\n      <td>185</td>\n      <td>35</td>\n      <td>22</td>\n      <td>160</td>\n      <td>202</td>\n      <td>518</td>\n      <td>178</td>\n      <td>62</td>\n      <td>13</td>\n      <td>8</td>\n      <td>198</td>\n      <td>208</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>763</td>\n      <td>102</td>\n      <td>52</td>\n      <td>98</td>\n      <td>225</td>\n      <td>71</td>\n      <td>10</td>\n      <td>214</td>\n      <td>31</td>\n      <td>24</td>\n      <td>164</td>\n      <td>228</td>\n      <td>682</td>\n      <td>199</td>\n      <td>71</td>\n      <td>0</td>\n      <td>16</td>\n      <td>187</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>201</td>\n      <td>90</td>\n      <td>36</td>\n      <td>74</td>\n      <td>171</td>\n      <td>60</td>\n      <td>8</td>\n      <td>157</td>\n      <td>42</td>\n      <td>19</td>\n      <td>128</td>\n      <td>177</td>\n      <td>367</td>\n      <td>123</td>\n      <td>61</td>\n      <td>6</td>\n      <td>21</td>\n      <td>197</td>\n      <td>204</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>818</td>\n      <td>95</td>\n      <td>43</td>\n      <td>96</td>\n      <td>202</td>\n      <td>65</td>\n      <td>10</td>\n      <td>189</td>\n      <td>35</td>\n      <td>22</td>\n      <td>143</td>\n      <td>217</td>\n      <td>534</td>\n      <td>166</td>\n      <td>71</td>\n      <td>6</td>\n      <td>27</td>\n      <td>190</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>306</td>\n      <td>106</td>\n      <td>48</td>\n      <td>107</td>\n      <td>202</td>\n      <td>61</td>\n      <td>10</td>\n      <td>207</td>\n      <td>32</td>\n      <td>24</td>\n      <td>153</td>\n      <td>227</td>\n      <td>635</td>\n      <td>200</td>\n      <td>70</td>\n      <td>5</td>\n      <td>28</td>\n      <td>190</td>\n      <td>203</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>285</td>\n      <td>89</td>\n      <td>48</td>\n      <td>85</td>\n      <td>189</td>\n      <td>64</td>\n      <td>8</td>\n      <td>169</td>\n      <td>39</td>\n      <td>20</td>\n      <td>153</td>\n      <td>188</td>\n      <td>427</td>\n      <td>190</td>\n      <td>64</td>\n      <td>16</td>\n      <td>5</td>\n      <td>195</td>\n      <td>201</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# First 15 rows of our dataset.\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98e7d91d77d65fcf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Methods `describe` and `info` deliver some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   421.249545   93.347905   44.515483   81.347905  168.231330   61.748634   \n",
       "std    244.485132    8.149890    6.073623   15.551571   33.409198    7.486888   \n",
       "min      5.000000   73.000000   34.000000   42.000000  105.000000   48.000000   \n",
       "25%    209.000000   87.000000   39.000000   70.000000  139.000000   57.000000   \n",
       "50%    420.000000   92.000000   44.000000   78.000000  167.000000   61.000000   \n",
       "75%    628.000000   99.000000   49.000000   96.000000  195.000000   65.000000   \n",
       "max    845.000000  119.000000   58.000000  112.000000  333.000000  138.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean     8.408015  167.442623   41.236794   20.468124  147.194900  187.508197   \n",
       "std      4.279173   32.689857    7.748465    2.554762   14.175654   31.216901   \n",
       "min      3.000000  114.000000   26.000000   17.000000  119.000000  131.000000   \n",
       "25%      6.000000  146.000000   34.000000   19.000000  136.000000  167.000000   \n",
       "50%      8.000000  157.000000   43.000000   20.000000  145.000000  177.000000   \n",
       "75%     10.000000  193.000000   46.000000   22.000000  158.000000  214.000000   \n",
       "max     55.000000  265.000000   59.000000   29.000000  182.000000  320.000000   \n",
       "\n",
       "                12          13          14          15          16  \\\n",
       "count   549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean    432.495446  173.054645   72.479053    6.204007   12.856102   \n",
       "std     173.456421   32.386139    7.231951    4.892112    9.162924   \n",
       "min     191.000000  112.000000   59.000000    0.000000    0.000000   \n",
       "25%     318.000000  148.000000   67.000000    2.000000    5.000000   \n",
       "50%     362.000000  172.000000   72.000000    5.000000   11.000000   \n",
       "75%     570.000000  195.000000   75.000000    9.000000   19.000000   \n",
       "max    1018.000000  268.000000  135.000000   22.000000   41.000000   \n",
       "\n",
       "               17          18  \n",
       "count  549.000000  549.000000  \n",
       "mean   188.969035  195.579235  \n",
       "std      6.173950    7.432396  \n",
       "min    176.000000  181.000000  \n",
       "25%    184.000000  190.000000  \n",
       "50%    189.000000  197.000000  \n",
       "75%    193.000000  201.000000  \n",
       "max    206.000000  211.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>421.249545</td>\n      <td>93.347905</td>\n      <td>44.515483</td>\n      <td>81.347905</td>\n      <td>168.231330</td>\n      <td>61.748634</td>\n      <td>8.408015</td>\n      <td>167.442623</td>\n      <td>41.236794</td>\n      <td>20.468124</td>\n      <td>147.194900</td>\n      <td>187.508197</td>\n      <td>432.495446</td>\n      <td>173.054645</td>\n      <td>72.479053</td>\n      <td>6.204007</td>\n      <td>12.856102</td>\n      <td>188.969035</td>\n      <td>195.579235</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>244.485132</td>\n      <td>8.149890</td>\n      <td>6.073623</td>\n      <td>15.551571</td>\n      <td>33.409198</td>\n      <td>7.486888</td>\n      <td>4.279173</td>\n      <td>32.689857</td>\n      <td>7.748465</td>\n      <td>2.554762</td>\n      <td>14.175654</td>\n      <td>31.216901</td>\n      <td>173.456421</td>\n      <td>32.386139</td>\n      <td>7.231951</td>\n      <td>4.892112</td>\n      <td>9.162924</td>\n      <td>6.173950</td>\n      <td>7.432396</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.000000</td>\n      <td>73.000000</td>\n      <td>34.000000</td>\n      <td>42.000000</td>\n      <td>105.000000</td>\n      <td>48.000000</td>\n      <td>3.000000</td>\n      <td>114.000000</td>\n      <td>26.000000</td>\n      <td>17.000000</td>\n      <td>119.000000</td>\n      <td>131.000000</td>\n      <td>191.000000</td>\n      <td>112.000000</td>\n      <td>59.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>176.000000</td>\n      <td>181.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>209.000000</td>\n      <td>87.000000</td>\n      <td>39.000000</td>\n      <td>70.000000</td>\n      <td>139.000000</td>\n      <td>57.000000</td>\n      <td>6.000000</td>\n      <td>146.000000</td>\n      <td>34.000000</td>\n      <td>19.000000</td>\n      <td>136.000000</td>\n      <td>167.000000</td>\n      <td>318.000000</td>\n      <td>148.000000</td>\n      <td>67.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>184.000000</td>\n      <td>190.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>420.000000</td>\n      <td>92.000000</td>\n      <td>44.000000</td>\n      <td>78.000000</td>\n      <td>167.000000</td>\n      <td>61.000000</td>\n      <td>8.000000</td>\n      <td>157.000000</td>\n      <td>43.000000</td>\n      <td>20.000000</td>\n      <td>145.000000</td>\n      <td>177.000000</td>\n      <td>362.000000</td>\n      <td>172.000000</td>\n      <td>72.000000</td>\n      <td>5.000000</td>\n      <td>11.000000</td>\n      <td>189.000000</td>\n      <td>197.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>628.000000</td>\n      <td>99.000000</td>\n      <td>49.000000</td>\n      <td>96.000000</td>\n      <td>195.000000</td>\n      <td>65.000000</td>\n      <td>10.000000</td>\n      <td>193.000000</td>\n      <td>46.000000</td>\n      <td>22.000000</td>\n      <td>158.000000</td>\n      <td>214.000000</td>\n      <td>570.000000</td>\n      <td>195.000000</td>\n      <td>75.000000</td>\n      <td>9.000000</td>\n      <td>19.000000</td>\n      <td>193.000000</td>\n      <td>201.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>845.000000</td>\n      <td>119.000000</td>\n      <td>58.000000</td>\n      <td>112.000000</td>\n      <td>333.000000</td>\n      <td>138.000000</td>\n      <td>55.000000</td>\n      <td>265.000000</td>\n      <td>59.000000</td>\n      <td>29.000000</td>\n      <td>182.000000</td>\n      <td>320.000000</td>\n      <td>1018.000000</td>\n      <td>268.000000</td>\n      <td>135.000000</td>\n      <td>22.000000</td>\n      <td>41.000000</td>\n      <td>206.000000</td>\n      <td>211.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 549 entries, 0 to 548\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype\n---  ------  --------------  -----\n 0   0       549 non-null    int32\n 1   1       549 non-null    int32\n 2   2       549 non-null    int32\n 3   3       549 non-null    int32\n 4   4       549 non-null    int32\n 5   5       549 non-null    int32\n 6   6       549 non-null    int32\n 7   7       549 non-null    int32\n 8   8       549 non-null    int32\n 9   9       549 non-null    int32\n 10  10      549 non-null    int32\n 11  11      549 non-null    int32\n 12  12      549 non-null    int32\n 13  13      549 non-null    int32\n 14  14      549 non-null    int32\n 15  15      549 non-null    int32\n 16  16      549 non-null    int32\n 17  17      549 non-null    int32\n 18  18      549 non-null    int32\ndtypes: int32(19)\nmemory usage: 40.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be844269be69c387",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2. Machine Learning pipeline\n",
    "Here you are supposed to perform the desired transformations. Please, explain your results briefly after each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0. Data preprocessing\n",
    "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a1514aa189a49fca",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean     0.011483    0.190797    0.150168    0.209920    0.058081    0.074074   \n",
       "std      0.583613    0.697336    0.630429    0.619503    0.600093    1.074154   \n",
       "min     -1.002387   -1.333333   -1.100000   -1.461538   -1.125000   -1.750000   \n",
       "25%     -0.491647   -0.333333   -0.300000   -0.269231   -0.392857   -0.625000   \n",
       "50%      0.019093    0.083333    0.100000    0.153846    0.017857    0.000000   \n",
       "75%      0.553699    0.750000    0.700000    0.846154    0.535714    0.500000   \n",
       "max      1.011933    1.916667    1.500000    1.230769    2.767857    9.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean     0.215488    0.306827   -0.218855    0.264871    0.203857    0.291282   \n",
       "std      1.284601    0.726657    0.659120    0.883718    0.683425    0.673833   \n",
       "min     -1.500000   -0.957447   -1.416667   -1.000000   -1.227273   -1.000000   \n",
       "25%     -0.250000   -0.212766   -0.916667   -0.333333   -0.227273   -0.191489   \n",
       "50%      0.000000    0.021277   -0.083333    0.000000    0.090909    0.063830   \n",
       "75%      0.500000    0.957447    0.250000    1.000000    0.772727    0.872340   \n",
       "max     11.000000    2.234043    1.500000    2.666667    1.954545    2.361702   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean     0.363570    0.122358    0.053872    0.242424    0.080327   -0.014964   \n",
       "std      0.722321    0.695250    0.993668    0.708409    0.605784    0.683918   \n",
       "min     -0.706349   -1.340426   -1.375000   -0.714286   -0.785714   -1.444444   \n",
       "25%     -0.170635   -0.404255   -0.625000   -0.285714   -0.357143   -0.444444   \n",
       "50%      0.027778    0.085106   -0.125000    0.142857    0.000000   -0.111111   \n",
       "75%      0.988095    0.617021    0.500000    0.714286    0.428571    0.444444   \n",
       "max      2.523810    1.893617    6.875000    2.428571    1.928571    1.666667   \n",
       "\n",
       "               18  \n",
       "count  297.000000  \n",
       "mean    -0.115396  \n",
       "std      0.678379  \n",
       "min     -1.363636  \n",
       "25%     -0.545455  \n",
       "50%      0.000000  \n",
       "75%      0.363636  \n",
       "max      1.272727  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n      <td>297.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.011483</td>\n      <td>0.190797</td>\n      <td>0.150168</td>\n      <td>0.209920</td>\n      <td>0.058081</td>\n      <td>0.074074</td>\n      <td>0.215488</td>\n      <td>0.306827</td>\n      <td>-0.218855</td>\n      <td>0.264871</td>\n      <td>0.203857</td>\n      <td>0.291282</td>\n      <td>0.363570</td>\n      <td>0.122358</td>\n      <td>0.053872</td>\n      <td>0.242424</td>\n      <td>0.080327</td>\n      <td>-0.014964</td>\n      <td>-0.115396</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.583613</td>\n      <td>0.697336</td>\n      <td>0.630429</td>\n      <td>0.619503</td>\n      <td>0.600093</td>\n      <td>1.074154</td>\n      <td>1.284601</td>\n      <td>0.726657</td>\n      <td>0.659120</td>\n      <td>0.883718</td>\n      <td>0.683425</td>\n      <td>0.673833</td>\n      <td>0.722321</td>\n      <td>0.695250</td>\n      <td>0.993668</td>\n      <td>0.708409</td>\n      <td>0.605784</td>\n      <td>0.683918</td>\n      <td>0.678379</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.002387</td>\n      <td>-1.333333</td>\n      <td>-1.100000</td>\n      <td>-1.461538</td>\n      <td>-1.125000</td>\n      <td>-1.750000</td>\n      <td>-1.500000</td>\n      <td>-0.957447</td>\n      <td>-1.416667</td>\n      <td>-1.000000</td>\n      <td>-1.227273</td>\n      <td>-1.000000</td>\n      <td>-0.706349</td>\n      <td>-1.340426</td>\n      <td>-1.375000</td>\n      <td>-0.714286</td>\n      <td>-0.785714</td>\n      <td>-1.444444</td>\n      <td>-1.363636</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.491647</td>\n      <td>-0.333333</td>\n      <td>-0.300000</td>\n      <td>-0.269231</td>\n      <td>-0.392857</td>\n      <td>-0.625000</td>\n      <td>-0.250000</td>\n      <td>-0.212766</td>\n      <td>-0.916667</td>\n      <td>-0.333333</td>\n      <td>-0.227273</td>\n      <td>-0.191489</td>\n      <td>-0.170635</td>\n      <td>-0.404255</td>\n      <td>-0.625000</td>\n      <td>-0.285714</td>\n      <td>-0.357143</td>\n      <td>-0.444444</td>\n      <td>-0.545455</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.019093</td>\n      <td>0.083333</td>\n      <td>0.100000</td>\n      <td>0.153846</td>\n      <td>0.017857</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.021277</td>\n      <td>-0.083333</td>\n      <td>0.000000</td>\n      <td>0.090909</td>\n      <td>0.063830</td>\n      <td>0.027778</td>\n      <td>0.085106</td>\n      <td>-0.125000</td>\n      <td>0.142857</td>\n      <td>0.000000</td>\n      <td>-0.111111</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.553699</td>\n      <td>0.750000</td>\n      <td>0.700000</td>\n      <td>0.846154</td>\n      <td>0.535714</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.957447</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>0.772727</td>\n      <td>0.872340</td>\n      <td>0.988095</td>\n      <td>0.617021</td>\n      <td>0.500000</td>\n      <td>0.714286</td>\n      <td>0.428571</td>\n      <td>0.444444</td>\n      <td>0.363636</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.011933</td>\n      <td>1.916667</td>\n      <td>1.500000</td>\n      <td>1.230769</td>\n      <td>2.767857</td>\n      <td>9.000000</td>\n      <td>11.000000</td>\n      <td>2.234043</td>\n      <td>1.500000</td>\n      <td>2.666667</td>\n      <td>1.954545</td>\n      <td>2.361702</td>\n      <td>2.523810</td>\n      <td>1.893617</td>\n      <td>6.875000</td>\n      <td>2.428571</td>\n      <td>1.928571</td>\n      <td>1.666667</td>\n      <td>1.272727</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "pd.DataFrame(X_test_norm).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_le = le.transform(y_train)\n",
    "y_test_le = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 2, 1, 3, 3, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y_test_le[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['bus', 'opel', 'saab', 'van'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Basic logistic regression\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the `train` data (small grid/random search is enough, no need to find the *best* parameters).\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` `tol=1e-3` and ` max_iter=500`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1dd5ad5d0845cbbb",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'max_iter': array([ 400.        ,  577.77777778,  755.55555556,  933.33333333,\n",
       "       1111.11111111, 1288.88888889, 1466.66666667, 1644.44444444,\n",
       "       1822.22222222, 2000.        ]),\n",
       "                         'solver': ['liblinear', 'newton-cg', 'lbfgs', 'saga'],\n",
       "                         'tol': array([1.00000000e-05, 2.63252632e-02, 5.26405263e-02, 7.89557895e-02,\n",
       "       1.05271053e-01, 1.31586316e-01, 1.57901579e-01, 1.84216842e-01,\n",
       "       2.10532105e-01, 2.36847368e-01, 2.63162632e-01, 2.89477895e-01,\n",
       "       3.15793158e-01, 3.42108421e-01, 3.68423684e-01, 3.94738947e-01,\n",
       "       4.21054211e-01, 4.47369474e-01, 4.73684737e-01, 5.00000000e-01])},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "\n",
    "clf = LogisticRegression(random_state=43, max_iter=1000)\n",
    "# clf.fit(X_train_norm, y_train_le)\n",
    "\n",
    "params_grid = {\n",
    "    \"solver\": [\"liblinear\", \"newton-cg\", \"lbfgs\", \"saga\"],\n",
    "    # \"solver\": [\"saga\"],\n",
    "    \"tol\": np.linspace(0.00001, 0.5, 20),\n",
    "    \"max_iter\": np.linspace(400, 2000, 10)\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(),params_grid, cv=5, scoring='f1_weighted')\n",
    "\n",
    "clf.fit(X_train_norm, y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_iter': 400.0, 'solver': 'lbfgs', 'tol': 0.4210542105263158}"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy:  0.7777777777777778\nf1 score: 0.7728610332438453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y_test_le, y_pred))\n",
    "print(\"f1 score:\", f1_score(y_test_le, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\MazenHassani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'max_iter': array([ 400.        ,  577.77777778,  755.55555556,  933.33333333,\n",
       "       1111.11111111, 1288.88888889, 1466.66666667, 1644.44444444,\n",
       "       1822.22222222, 2000.        ]),\n",
       "                         'solver': ['liblinear', 'newton-cg', 'lbfgs', 'saga'],\n",
       "                         'tol': array([1.00000000e-05, 2.63252632e-02, 5.26405263e-02, 7.89557895e-02,\n",
       "       1.05271053e-01, 1.31586316e-01, 1.57901579e-01, 1.84216842e-01,\n",
       "       2.10532105e-01, 2.36847368e-01, 2.63162632e-01, 2.89477895e-01,\n",
       "       3.15793158e-01, 3.42108421e-01, 3.68423684e-01, 3.94738947e-01,\n",
       "       4.21054211e-01, 4.47369474e-01, 4.73684737e-01, 5.00000000e-01])},\n",
       "             scoring='accuracy')"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "clf2 = GridSearchCV(LogisticRegression(),params_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "clf2.fit(X_train_norm, y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_iter': 400.0, 'solver': 'newton-cg', 'tol': 1e-05}"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "clf2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf2.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy:  0.7777777777777778\nf1 score: 0.7728610332438453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y_test_le, y_pred))\n",
    "print(\"f1 score:\", f1_score(y_test_le, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500, multi_class='multinomial', random_state=43,\n",
       "                   solver='saga', tol=0.001)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "clf3 = LogisticRegression (multi_class='multinomial', solver='saga', tol=1e-3, max_iter=500, random_state=43)\n",
    "clf3.fit(X_train_norm, y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy3:  0.7777777777777778\nf1 score3: 0.7726223121408425\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = clf3.predict(X_test_norm)\n",
    "print(\"accuracy3: \", accuracy_score(y_test_le, y_pred3))\n",
    "print(\"f1 score3:\", f1_score(y_test_le, y_pred3, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might use this command to install scikit-plot. \n",
    "# Warning, if you a running locally, don't call pip from within jupyter, call it from terminal in the corresponding \n",
    "# virtual environment instead\n",
    "\n",
    "# ! pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. PCA: explained variance plot\n",
    "* Apply the PCA to the train part of the data. Build the explaided variance plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c6c614740bce090e",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c1fe666f52fe53c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.3. PCA trasformation\n",
    "* Select the appropriate number of components. Briefly explain your choice. Should you normalize the data?\n",
    "\n",
    "*Use `fit` and `transform` methods to transform the `train` and `test` parts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96ab18d96473ef71",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: From this point `sklearn` [Pipeline](https://scikit-learn.org/stable/modules/compose.html) might be useful to perform transformations on the data. Refer to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d28b58a35c94e988",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.4. Logistic regression on PCA-preprocessed data.\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the transformed by PCA `train` data.\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` and `tol=1e-3`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-12d53ea45258fa82",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fbf16c64076e139",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.5. Decision tree\n",
    "* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation.\n",
    "\n",
    "* Measure the model quality using the same metrics you used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-748ed20b51c67fab",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eadd4d8a03ae67a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.6. Bagging.\n",
    "Here starts the ensembling part.\n",
    "\n",
    "First we will use the __Bagging__ approach. Build an ensemble of $N$ algorithms varying N from $N_{min}=2$ to $N_{max}=100$ (with step 5).\n",
    "\n",
    "We will build two ensembles: of logistic regressions and of decision trees.\n",
    "\n",
    "*Comment: each ensemble should be constructed from models of the same family, so logistic regressions should not be mixed up with decision trees.*\n",
    "\n",
    "\n",
    "*Hint 1: To build a __Bagging__ ensebmle varying the ensemble size efficiently you might generate $N_{max}$ subsets of `train` data (of the same size as the original dataset) using bootstrap procedure once. Then you train a new instance of logistic regression/decision tree with optimal hyperparameters you estimated before on each subset (so you train it from scratch). Finally, to get an ensemble of $N$ models you average the $N$ out of $N_{max}$ models predictions.*\n",
    "\n",
    "*Hint 2: sklearn might help you with this taks. Some appropriate function/class might be out there.*\n",
    "\n",
    "* Plot `f1` and `accuracy` scores plots w.r.t. the size of the ensemble.\n",
    "\n",
    "* Briefly analyse the plot. What is the optimal number of algorithms? Explain your answer.\n",
    "\n",
    "* How do you think, are the hyperparameters for the decision trees you found in 2.5 optimal for trees used in ensemble? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8fc95a2b206bdae1",
     "locked": false,
     "points": 35,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-241b7691ab44cbfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.7. Random Forest\n",
    "Now we will work with the Random Forest (its `sklearn` implementation).\n",
    "\n",
    "* * Plot `f1` and `accuracy` scores plots w.r.t. the number of trees in Random Forest.\n",
    "\n",
    "* What is the optimal number of trees you've got? Is it different from the optimal number of logistic regressions/decision trees in 2.6? Explain the results briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-888755d0f3d91620",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99191c0852538d4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.8. Learning curve\n",
    "Your goal is to estimate, how does the model behaviour change with the increase of the `train` dataset size.\n",
    "\n",
    "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
    "\n",
    "* Build a plot of `accuracy` and `f1` scores on `test` part, varying the `train` dataset size (so the axes will be score - dataset size.\n",
    "\n",
    "* Analyse the final plot. Can you make any conlusions using it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e39bc7e7dff61ff9",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4646ac7e83cbcee5f45a88b92c8359e7729e33d2e26239ae4b7b4025fb7e9a61"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}