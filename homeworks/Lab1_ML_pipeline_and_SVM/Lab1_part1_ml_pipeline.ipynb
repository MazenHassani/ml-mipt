{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment â„–1, part 1\n",
    "\n",
    "This lab assignment consists of several parts. You are supposed to make some transformations, train some models, estimate the quality of the models and explain your results.\n",
    "\n",
    "Several comments:\n",
    "* Don't hesitate to ask questions, it's a good practice.\n",
    "* No private/public sharing, please. The copied assignments will be graded with 0 points.\n",
    "* Blocks of this lab will be graded separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*This is the first part of the assignment. Second part is waiting for you in the same directory.*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-512ba712fc0fc065",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Part 1. Data preprocessing, model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b656a4266174b009",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1. Reading the data\n",
    "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If on colab, uncomment the following lines\n",
    "\n",
    "# ! wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/basic_f20/homeworks_basic/Lab1_ML_pipeline_and_SVM/car_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(846, 19) (846,)\n(549, 19) (549,) (297, 19) (297,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88b1a0f688568f2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     0    1   2    3    4   5   6    7   8   9    10   11   12   13  14  15  \\\n",
       "0   141   81  42   63  125  55   8  149  46  19  145  166  320  172  86   7   \n",
       "1   505  115  53  100  205  64  11  220  30  25  166  229  710  214  71  21   \n",
       "2   650   98  55  104  213  67   9  206  32  23  167  223  629  220  72   5   \n",
       "3   472  105  50   93  173  54   4  222  30  25  159  254  735  206  83   4   \n",
       "4   573   89  47   80  131  54  11  160  43  20  163  175  369  174  77   1   \n",
       "5   538  101  49  103  212  67  10  201  33  23  156  215  601  174  69   4   \n",
       "6   468  105  51  108  201  62  11  220  30  25  163  232  711  202  72  12   \n",
       "7   443   99  50   88  204  64  10  185  35  22  159  209  517  193  66  12   \n",
       "8   498   88  36   53  113  57   3  118  57  17  128  137  204  136  88   7   \n",
       "9   702   96  48   83  177  59   8  171  39  21  152  195  438  196  67  15   \n",
       "10  670   95  51   96  196  63   9  190  35  22  161  208  543  235  68  13   \n",
       "11  345  101  54  106  188  57   7  236  28  26  164  256  833  253  81   6   \n",
       "12  499  102  54   98  167  53  10  217  31  24  174  228  692  223  72   0   \n",
       "13   17   99  41   77  197  69   6  177  36  21  139  202  485  151  72   4   \n",
       "14  821  104  56   96  231  74  11  220  30  25  172  223  713  218  73   6   \n",
       "\n",
       "    16   17   18  \n",
       "0    7  179  182  \n",
       "1   11  189  199  \n",
       "2   19  187  196  \n",
       "3   12  186  184  \n",
       "4    7  182  193  \n",
       "5   11  189  196  \n",
       "6   16  189  200  \n",
       "7   11  194  201  \n",
       "8   14  180  183  \n",
       "9    0  195  201  \n",
       "10   0  191  198  \n",
       "11  14  185  185  \n",
       "12  31  187  198  \n",
       "13  10  198  199  \n",
       "14  16  186  195  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>141</td>\n      <td>81</td>\n      <td>42</td>\n      <td>63</td>\n      <td>125</td>\n      <td>55</td>\n      <td>8</td>\n      <td>149</td>\n      <td>46</td>\n      <td>19</td>\n      <td>145</td>\n      <td>166</td>\n      <td>320</td>\n      <td>172</td>\n      <td>86</td>\n      <td>7</td>\n      <td>7</td>\n      <td>179</td>\n      <td>182</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>505</td>\n      <td>115</td>\n      <td>53</td>\n      <td>100</td>\n      <td>205</td>\n      <td>64</td>\n      <td>11</td>\n      <td>220</td>\n      <td>30</td>\n      <td>25</td>\n      <td>166</td>\n      <td>229</td>\n      <td>710</td>\n      <td>214</td>\n      <td>71</td>\n      <td>21</td>\n      <td>11</td>\n      <td>189</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>650</td>\n      <td>98</td>\n      <td>55</td>\n      <td>104</td>\n      <td>213</td>\n      <td>67</td>\n      <td>9</td>\n      <td>206</td>\n      <td>32</td>\n      <td>23</td>\n      <td>167</td>\n      <td>223</td>\n      <td>629</td>\n      <td>220</td>\n      <td>72</td>\n      <td>5</td>\n      <td>19</td>\n      <td>187</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>472</td>\n      <td>105</td>\n      <td>50</td>\n      <td>93</td>\n      <td>173</td>\n      <td>54</td>\n      <td>4</td>\n      <td>222</td>\n      <td>30</td>\n      <td>25</td>\n      <td>159</td>\n      <td>254</td>\n      <td>735</td>\n      <td>206</td>\n      <td>83</td>\n      <td>4</td>\n      <td>12</td>\n      <td>186</td>\n      <td>184</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>573</td>\n      <td>89</td>\n      <td>47</td>\n      <td>80</td>\n      <td>131</td>\n      <td>54</td>\n      <td>11</td>\n      <td>160</td>\n      <td>43</td>\n      <td>20</td>\n      <td>163</td>\n      <td>175</td>\n      <td>369</td>\n      <td>174</td>\n      <td>77</td>\n      <td>1</td>\n      <td>7</td>\n      <td>182</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>538</td>\n      <td>101</td>\n      <td>49</td>\n      <td>103</td>\n      <td>212</td>\n      <td>67</td>\n      <td>10</td>\n      <td>201</td>\n      <td>33</td>\n      <td>23</td>\n      <td>156</td>\n      <td>215</td>\n      <td>601</td>\n      <td>174</td>\n      <td>69</td>\n      <td>4</td>\n      <td>11</td>\n      <td>189</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>468</td>\n      <td>105</td>\n      <td>51</td>\n      <td>108</td>\n      <td>201</td>\n      <td>62</td>\n      <td>11</td>\n      <td>220</td>\n      <td>30</td>\n      <td>25</td>\n      <td>163</td>\n      <td>232</td>\n      <td>711</td>\n      <td>202</td>\n      <td>72</td>\n      <td>12</td>\n      <td>16</td>\n      <td>189</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>443</td>\n      <td>99</td>\n      <td>50</td>\n      <td>88</td>\n      <td>204</td>\n      <td>64</td>\n      <td>10</td>\n      <td>185</td>\n      <td>35</td>\n      <td>22</td>\n      <td>159</td>\n      <td>209</td>\n      <td>517</td>\n      <td>193</td>\n      <td>66</td>\n      <td>12</td>\n      <td>11</td>\n      <td>194</td>\n      <td>201</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>498</td>\n      <td>88</td>\n      <td>36</td>\n      <td>53</td>\n      <td>113</td>\n      <td>57</td>\n      <td>3</td>\n      <td>118</td>\n      <td>57</td>\n      <td>17</td>\n      <td>128</td>\n      <td>137</td>\n      <td>204</td>\n      <td>136</td>\n      <td>88</td>\n      <td>7</td>\n      <td>14</td>\n      <td>180</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>702</td>\n      <td>96</td>\n      <td>48</td>\n      <td>83</td>\n      <td>177</td>\n      <td>59</td>\n      <td>8</td>\n      <td>171</td>\n      <td>39</td>\n      <td>21</td>\n      <td>152</td>\n      <td>195</td>\n      <td>438</td>\n      <td>196</td>\n      <td>67</td>\n      <td>15</td>\n      <td>0</td>\n      <td>195</td>\n      <td>201</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>670</td>\n      <td>95</td>\n      <td>51</td>\n      <td>96</td>\n      <td>196</td>\n      <td>63</td>\n      <td>9</td>\n      <td>190</td>\n      <td>35</td>\n      <td>22</td>\n      <td>161</td>\n      <td>208</td>\n      <td>543</td>\n      <td>235</td>\n      <td>68</td>\n      <td>13</td>\n      <td>0</td>\n      <td>191</td>\n      <td>198</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>345</td>\n      <td>101</td>\n      <td>54</td>\n      <td>106</td>\n      <td>188</td>\n      <td>57</td>\n      <td>7</td>\n      <td>236</td>\n      <td>28</td>\n      <td>26</td>\n      <td>164</td>\n      <td>256</td>\n      <td>833</td>\n      <td>253</td>\n      <td>81</td>\n      <td>6</td>\n      <td>14</td>\n      <td>185</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>499</td>\n      <td>102</td>\n      <td>54</td>\n      <td>98</td>\n      <td>167</td>\n      <td>53</td>\n      <td>10</td>\n      <td>217</td>\n      <td>31</td>\n      <td>24</td>\n      <td>174</td>\n      <td>228</td>\n      <td>692</td>\n      <td>223</td>\n      <td>72</td>\n      <td>0</td>\n      <td>31</td>\n      <td>187</td>\n      <td>198</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>17</td>\n      <td>99</td>\n      <td>41</td>\n      <td>77</td>\n      <td>197</td>\n      <td>69</td>\n      <td>6</td>\n      <td>177</td>\n      <td>36</td>\n      <td>21</td>\n      <td>139</td>\n      <td>202</td>\n      <td>485</td>\n      <td>151</td>\n      <td>72</td>\n      <td>4</td>\n      <td>10</td>\n      <td>198</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>821</td>\n      <td>104</td>\n      <td>56</td>\n      <td>96</td>\n      <td>231</td>\n      <td>74</td>\n      <td>11</td>\n      <td>220</td>\n      <td>30</td>\n      <td>25</td>\n      <td>172</td>\n      <td>223</td>\n      <td>713</td>\n      <td>218</td>\n      <td>73</td>\n      <td>6</td>\n      <td>16</td>\n      <td>186</td>\n      <td>195</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# First 15 rows of our dataset.\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98e7d91d77d65fcf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Methods `describe` and `info` deliver some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   419.928962   93.719490   45.001821   82.537341  170.326047   61.965392   \n",
       "std    246.916592    8.371921    6.207336   15.767036   34.313035    8.576655   \n",
       "min      0.000000   73.000000   33.000000   40.000000  104.000000   47.000000   \n",
       "25%    200.000000   87.000000   40.000000   70.000000  142.000000   57.000000   \n",
       "50%    424.000000   93.000000   44.000000   80.000000  169.000000   61.000000   \n",
       "75%    633.000000  100.000000   50.000000   98.000000  197.000000   66.000000   \n",
       "max    845.000000  119.000000   59.000000  112.000000  333.000000  138.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean     8.590164  170.065574   40.633880   20.659381  148.335155  189.959927   \n",
       "std      4.747413   33.559775    7.808078    2.626821   14.555477   31.952037   \n",
       "min      3.000000  112.000000   26.000000   17.000000  118.000000  130.000000   \n",
       "25%      6.000000  147.000000   33.000000   19.000000  137.000000  168.000000   \n",
       "50%      8.000000  157.000000   43.000000   20.000000  146.000000  180.000000   \n",
       "75%     10.000000  201.000000   46.000000   23.000000  160.000000  217.000000   \n",
       "max     52.000000  265.000000   61.000000   29.000000  188.000000  320.000000   \n",
       "\n",
       "                12          13          14          15          16  \\\n",
       "count   549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean    446.570128  175.209472   72.617486    6.238616   12.825137   \n",
       "std     179.352864   32.788776    7.605424    4.758730    8.752186   \n",
       "min     184.000000  112.000000   60.000000    0.000000    0.000000   \n",
       "25%     321.000000  151.000000   67.000000    2.000000    6.000000   \n",
       "50%     365.000000  173.000000   72.000000    6.000000   12.000000   \n",
       "75%     602.000000  198.000000   76.000000    9.000000   19.000000   \n",
       "max    1018.000000  268.000000  135.000000   22.000000   41.000000   \n",
       "\n",
       "               17          18  \n",
       "count  549.000000  549.000000  \n",
       "mean   188.932605  195.562842  \n",
       "std      6.178682    7.469290  \n",
       "min    176.000000  181.000000  \n",
       "25%    184.000000  190.000000  \n",
       "50%    188.000000  197.000000  \n",
       "75%    193.000000  201.000000  \n",
       "max    204.000000  211.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>419.928962</td>\n      <td>93.719490</td>\n      <td>45.001821</td>\n      <td>82.537341</td>\n      <td>170.326047</td>\n      <td>61.965392</td>\n      <td>8.590164</td>\n      <td>170.065574</td>\n      <td>40.633880</td>\n      <td>20.659381</td>\n      <td>148.335155</td>\n      <td>189.959927</td>\n      <td>446.570128</td>\n      <td>175.209472</td>\n      <td>72.617486</td>\n      <td>6.238616</td>\n      <td>12.825137</td>\n      <td>188.932605</td>\n      <td>195.562842</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>246.916592</td>\n      <td>8.371921</td>\n      <td>6.207336</td>\n      <td>15.767036</td>\n      <td>34.313035</td>\n      <td>8.576655</td>\n      <td>4.747413</td>\n      <td>33.559775</td>\n      <td>7.808078</td>\n      <td>2.626821</td>\n      <td>14.555477</td>\n      <td>31.952037</td>\n      <td>179.352864</td>\n      <td>32.788776</td>\n      <td>7.605424</td>\n      <td>4.758730</td>\n      <td>8.752186</td>\n      <td>6.178682</td>\n      <td>7.469290</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>73.000000</td>\n      <td>33.000000</td>\n      <td>40.000000</td>\n      <td>104.000000</td>\n      <td>47.000000</td>\n      <td>3.000000</td>\n      <td>112.000000</td>\n      <td>26.000000</td>\n      <td>17.000000</td>\n      <td>118.000000</td>\n      <td>130.000000</td>\n      <td>184.000000</td>\n      <td>112.000000</td>\n      <td>60.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>176.000000</td>\n      <td>181.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>200.000000</td>\n      <td>87.000000</td>\n      <td>40.000000</td>\n      <td>70.000000</td>\n      <td>142.000000</td>\n      <td>57.000000</td>\n      <td>6.000000</td>\n      <td>147.000000</td>\n      <td>33.000000</td>\n      <td>19.000000</td>\n      <td>137.000000</td>\n      <td>168.000000</td>\n      <td>321.000000</td>\n      <td>151.000000</td>\n      <td>67.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>184.000000</td>\n      <td>190.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>424.000000</td>\n      <td>93.000000</td>\n      <td>44.000000</td>\n      <td>80.000000</td>\n      <td>169.000000</td>\n      <td>61.000000</td>\n      <td>8.000000</td>\n      <td>157.000000</td>\n      <td>43.000000</td>\n      <td>20.000000</td>\n      <td>146.000000</td>\n      <td>180.000000</td>\n      <td>365.000000</td>\n      <td>173.000000</td>\n      <td>72.000000</td>\n      <td>6.000000</td>\n      <td>12.000000</td>\n      <td>188.000000</td>\n      <td>197.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>633.000000</td>\n      <td>100.000000</td>\n      <td>50.000000</td>\n      <td>98.000000</td>\n      <td>197.000000</td>\n      <td>66.000000</td>\n      <td>10.000000</td>\n      <td>201.000000</td>\n      <td>46.000000</td>\n      <td>23.000000</td>\n      <td>160.000000</td>\n      <td>217.000000</td>\n      <td>602.000000</td>\n      <td>198.000000</td>\n      <td>76.000000</td>\n      <td>9.000000</td>\n      <td>19.000000</td>\n      <td>193.000000</td>\n      <td>201.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>845.000000</td>\n      <td>119.000000</td>\n      <td>59.000000</td>\n      <td>112.000000</td>\n      <td>333.000000</td>\n      <td>138.000000</td>\n      <td>52.000000</td>\n      <td>265.000000</td>\n      <td>61.000000</td>\n      <td>29.000000</td>\n      <td>188.000000</td>\n      <td>320.000000</td>\n      <td>1018.000000</td>\n      <td>268.000000</td>\n      <td>135.000000</td>\n      <td>22.000000</td>\n      <td>41.000000</td>\n      <td>204.000000</td>\n      <td>211.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 549 entries, 0 to 548\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype\n---  ------  --------------  -----\n 0   0       549 non-null    int32\n 1   1       549 non-null    int32\n 2   2       549 non-null    int32\n 3   3       549 non-null    int32\n 4   4       549 non-null    int32\n 5   5       549 non-null    int32\n 6   6       549 non-null    int32\n 7   7       549 non-null    int32\n 8   8       549 non-null    int32\n 9   9       549 non-null    int32\n 10  10      549 non-null    int32\n 11  11      549 non-null    int32\n 12  12      549 non-null    int32\n 13  13      549 non-null    int32\n 14  14      549 non-null    int32\n 15  15      549 non-null    int32\n 16  16      549 non-null    int32\n 17  17      549 non-null    int32\n 18  18      549 non-null    int32\ndtypes: int32(19)\nmemory usage: 40.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be844269be69c387",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2. Machine Learning pipeline\n",
    "Here you are supposed to perform the desired transformations. Please, explain your results briefly after each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0. Data preprocessing\n",
    "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a1514aa189a49fca",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Basic logistic regression\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the `train` data (small grid/random search is enough, no need to find the *best* parameters).\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` `tol=1e-3` and ` max_iter=500`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1dd5ad5d0845cbbb",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might use this command to install scikit-plot. \n",
    "# Warning, if you a running locally, don't call pip from within jupyter, call it from terminal in the corresponding \n",
    "# virtual environment instead\n",
    "\n",
    "# ! pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. PCA: explained variance plot\n",
    "* Apply the PCA to the train part of the data. Build the explaided variance plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c6c614740bce090e",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c1fe666f52fe53c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.3. PCA trasformation\n",
    "* Select the appropriate number of components. Briefly explain your choice. Should you normalize the data?\n",
    "\n",
    "*Use `fit` and `transform` methods to transform the `train` and `test` parts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96ab18d96473ef71",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: From this point `sklearn` [Pipeline](https://scikit-learn.org/stable/modules/compose.html) might be useful to perform transformations on the data. Refer to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d28b58a35c94e988",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.4. Logistic regression on PCA-preprocessed data.\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the transformed by PCA `train` data.\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` and `tol=1e-3`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-12d53ea45258fa82",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fbf16c64076e139",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.5. Decision tree\n",
    "* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation.\n",
    "\n",
    "* Measure the model quality using the same metrics you used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-748ed20b51c67fab",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eadd4d8a03ae67a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.6. Bagging.\n",
    "Here starts the ensembling part.\n",
    "\n",
    "First we will use the __Bagging__ approach. Build an ensemble of $N$ algorithms varying N from $N_{min}=2$ to $N_{max}=100$ (with step 5).\n",
    "\n",
    "We will build two ensembles: of logistic regressions and of decision trees.\n",
    "\n",
    "*Comment: each ensemble should be constructed from models of the same family, so logistic regressions should not be mixed up with decision trees.*\n",
    "\n",
    "\n",
    "*Hint 1: To build a __Bagging__ ensebmle varying the ensemble size efficiently you might generate $N_{max}$ subsets of `train` data (of the same size as the original dataset) using bootstrap procedure once. Then you train a new instance of logistic regression/decision tree with optimal hyperparameters you estimated before on each subset (so you train it from scratch). Finally, to get an ensemble of $N$ models you average the $N$ out of $N_{max}$ models predictions.*\n",
    "\n",
    "*Hint 2: sklearn might help you with this taks. Some appropriate function/class might be out there.*\n",
    "\n",
    "* Plot `f1` and `accuracy` scores plots w.r.t. the size of the ensemble.\n",
    "\n",
    "* Briefly analyse the plot. What is the optimal number of algorithms? Explain your answer.\n",
    "\n",
    "* How do you think, are the hyperparameters for the decision trees you found in 2.5 optimal for trees used in ensemble? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8fc95a2b206bdae1",
     "locked": false,
     "points": 35,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-241b7691ab44cbfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.7. Random Forest\n",
    "Now we will work with the Random Forest (its `sklearn` implementation).\n",
    "\n",
    "* * Plot `f1` and `accuracy` scores plots w.r.t. the number of trees in Random Forest.\n",
    "\n",
    "* What is the optimal number of trees you've got? Is it different from the optimal number of logistic regressions/decision trees in 2.6? Explain the results briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-888755d0f3d91620",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99191c0852538d4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.8. Learning curve\n",
    "Your goal is to estimate, how does the model behaviour change with the increase of the `train` dataset size.\n",
    "\n",
    "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
    "\n",
    "* Build a plot of `accuracy` and `f1` scores on `test` part, varying the `train` dataset size (so the axes will be score - dataset size.\n",
    "\n",
    "* Analyse the final plot. Can you make any conlusions using it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e39bc7e7dff61ff9",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4646ac7e83cbcee5f45a88b92c8359e7729e33d2e26239ae4b7b4025fb7e9a61"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}